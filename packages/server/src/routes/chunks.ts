import express from 'express';
import { RecordingStorage } from '../storage/recording-storage.js';
import { StorageBackend } from '../storage/storage-backend.js';
import { blake3 } from '@noble/hashes/blake3.js';
import { bytesToHex } from '@noble/hashes/utils.js';

export function createChunksRouter(
  recordingStorage: RecordingStorage,
  chunkStorage: StorageBackend
): express.Router {
  const router = express.Router();

  /**
   * POST /api/recordings/:recording_id/chunks?chunk_id=123
   * ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
   */
  router.post(
    '/recordings/:recording_id/chunks',
    express.raw({ type: 'application/octet-stream', limit: '50mb' }),
    async (req, res): Promise<void> => {
      const { recording_id } = req.params;
      const chunk_id = req.query.chunk_id as string;

      // chunk_idã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
      if (!chunk_id) {
        res.status(400).json({ error: 'chunk_id query parameter is required' });
        return;
      }

      // Recordingã®å­˜åœ¨ç¢ºèª
      const recording = recordingStorage.getRecording(recording_id);
      if (!recording) {
        res.status(404).json({ error: 'Recording not found' });
        return;
      }

      // RecordingçŠ¶æ…‹ã®ç¢ºèª
      if (recording.state !== 'recording' && recording.state !== 'finalizing') {
        res.status(400).json({
          error: `Cannot upload chunks in state: ${recording.state}. Recording must be in 'recording' or 'finalizing' state.`
        });
        return;
      }

      // ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã®å–å¾—
      if (!Buffer.isBuffer(req.body)) {
        res.status(400).json({ error: 'Invalid request body. Expected binary data.' });
        return;
      }

      const data = req.body as Buffer;

      // ãƒãƒƒã‚·ãƒ¥ã®æ¤œè¨¼
      const clientHash = req.headers['x-chunk-hash'] as string;
      if (!clientHash) {
        res.status(400).json({ error: 'X-Chunk-Hash header is required' });
        return;
      }

      // ã‚µãƒ¼ãƒãƒ¼å´ã§ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
      const serverHashBytes = blake3(new Uint8Array(data));
      const serverHash = bytesToHex(serverHashBytes);

      // ãƒãƒƒã‚·ãƒ¥ã®ä¸€è‡´ç¢ºèª
      if (clientHash !== serverHash) {
        console.error(`âŒ Hash mismatch for chunk ${chunk_id}: client=${clientHash.substring(0, 16)}..., server=${serverHash.substring(0, 16)}...`);
        res.status(400).json({
          error: 'Hash verification failed',
          expected: serverHash,
          received: clientHash
        });
        return;
      }

      console.log(`ğŸ” [ChunkUpload] Hash verified for chunk ${chunk_id}: ${serverHash.substring(0, 16)}...`);

      try {
        // å†ªç­‰æ€§ãƒã‚§ãƒƒã‚¯: ãƒãƒ£ãƒ³ã‚¯ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        let chunkExists = false;
        try {
          const existingChunk = await chunkStorage.getChunk(recording_id, chunk_id);
          chunkExists = true;

          // æ—¢å­˜ãƒãƒ£ãƒ³ã‚¯ã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
          const existingHashBytes = blake3(new Uint8Array(existingChunk));
          const existingHash = bytesToHex(existingHashBytes);

          if (existingHash === serverHash) {
            // åŒã˜ãƒãƒ£ãƒ³ã‚¯ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ï¼ˆå†ªç­‰æ€§ï¼‰
            console.log(`âœ… [ChunkUpload] Chunk ${chunk_id} already exists with matching hash (idempotent)`);
            res.status(200).json({
              message: 'Chunk already exists (idempotent)',
              chunk_id,
              size: data.length
            });
            return;
          } else {
            // ãƒãƒƒã‚·ãƒ¥ãŒç•°ãªã‚‹å ´åˆã¯ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆ
            console.error(`âŒ [ChunkUpload] Chunk ${chunk_id} exists but hash differs`);
            res.status(409).json({
              error: 'Chunk already exists with different content',
              existing_hash: existingHash,
              new_hash: serverHash
            });
            return;
          }
        } catch (error) {
          // ãƒãƒ£ãƒ³ã‚¯ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç¶šè¡Œ
          if (error instanceof Error && error.message.includes('Chunk not found')) {
            chunkExists = false;
          } else {
            throw error;
          }
        }

        // ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
        await chunkStorage.putChunk(recording_id, chunk_id, data);

        // ãƒãƒ£ãƒ³ã‚¯ã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°ï¼ˆæ–°è¦ä¿å­˜ã®å ´åˆã®ã¿ï¼‰
        if (!chunkExists) {
          recordingStorage.incrementChunkCount(recording_id);
        }

        res.status(201).json({
          message: 'Chunk uploaded successfully',
          chunk_id,
          size: data.length,
          hash: serverHash
        });
      } catch (error) {
        console.error('Error uploading chunk:', error);
        res.status(500).json({ error: 'Failed to upload chunk' });
      }
    }
  );

  /**
   * GET /api/recordings/:recording_id/chunks/:chunk_id
   * ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆæ¤œè¨¼ç”¨ï¼‰
   */
  router.get('/recordings/:recording_id/chunks/:chunk_id', async (req, res): Promise<void> => {
    const { recording_id, chunk_id } = req.params;

    // Recordingã®å­˜åœ¨ç¢ºèª
    const recording = recordingStorage.getRecording(recording_id);
    if (!recording) {
      res.status(404).json({ error: 'Recording not found' });
      return;
    }

    try {
      const data = await chunkStorage.getChunk(recording_id, chunk_id);
      res.setHeader('Content-Type', 'application/octet-stream');
      res.send(data);
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      if (errorMessage.includes('Chunk not found')) {
        res.status(404).json({ error: 'Chunk not found' });
        return;
      }
      console.error('Error retrieving chunk:', error);
      res.status(500).json({ error: 'Failed to retrieve chunk' });
    }
  });

  return router;
}
